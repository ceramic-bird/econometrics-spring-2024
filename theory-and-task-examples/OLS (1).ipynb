{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод наименьших квадратов\n",
    "\n",
    "Рассмотрим переменные:\n",
    "\n",
    "* $y$ – зависимая переменная, отклик, __target__  (количественная!)\n",
    "* $\\begin{pmatrix} x_1 &\\cdots & x_k \\end{pmatrix}$ – объясняющие/влияющие переменные, регрессоры, предикторы, __features__ (количественные/категориальные)\n",
    "\n",
    "для которых имеем серию $n$ наблюдений: \n",
    "\n",
    "$$\\{y_i, x_{i1},\\ldots, x_{ik} \\}_{i=1}^n$$\n",
    "\n",
    "## Задача прогнозирования\n",
    "\n",
    "Рассмотрим функцию/модель $a(x_1,\\ldots,x_k)$, которую будем использовать для прогнозирования $y$ при заданных \n",
    "$\\begin{pmatrix} x_1 &\\cdots & x_k \\end{pmatrix}$.\n",
    "\n",
    "Обычно модель зависит то нескольких параметров $a(x_1,\\ldots,x_k)=a(x_1,\\ldots,x_k,\\beta)$.\n",
    "\n",
    "Прогноз обозначим $\\hat{y}=a(x_1,\\ldots,x_k)=a(x_1,\\ldots,x_k,\\beta)$\n",
    "\n",
    "__Задача__: на данных обучить выбранную модель, чтобы использовать её для прогнозирования на новых наблюдениях.\n",
    "\n",
    "Что нужно?\n",
    "\n",
    "1. Выбрать модель $a(x_1,\\ldots,x_k)$\n",
    "2. Выбрать функцию потерь $L(y,\\hat{y})$, показывающую точность прогнозирования\n",
    "\n",
    "__Подгонка модели__: решаем задачу оптимизации\n",
    "\n",
    "$$\n",
    "\t\\min_{\\beta} \\frac{1}{n}\\sum_{i=1}^n L(y_i,\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "Параметры подогнанной модели обозначим $\\hat{\\beta}$\n",
    "\n",
    "## Метод наименьших квадратов (OLS) для линейной регрессии\n",
    "\n",
    "В качестве модели для прогнозирования выборем __линейную регрессию__ (с константой)\n",
    "\n",
    "$$\n",
    "\ta(x_1,\\ldots,x_k)=\\beta_0+\\beta_1x_1+\\cdots+\\beta_kx_k\n",
    "$$\n",
    "\n",
    "Функция потерь $L(y,\\hat{y})=|y-\\hat{y}|^2$ (квадрат ошибки прогнозирования для наблюдения).  Она соответствует метрике MSE = Mean Squared Error\n",
    "\n",
    "Для удобства обозначим \n",
    "* $\\beta=\\begin{pmatrix} \\beta_0 & \\beta_1 & \\cdots & \\beta_k \\end{pmatrix}^\\top$\n",
    "* $x=\\begin{pmatrix} 1 & x_1 & \\cdots & x_k \\end{pmatrix}^\\top$\n",
    "\n",
    "Тогда $a(x_1,\\ldots,x_k)=x^\\top \\beta=\\langle x, \\beta\\rangle$\n",
    "\n",
    "__Подгонка модели (выбор коэффициентов)__: решаем задачу оптимизации\n",
    "\n",
    "$$\n",
    "\t\\min_{\\beta} \\frac{1}{n}\\sum_{i=1}^n |y_i-\\hat{y}_i|^2\n",
    "$$\n",
    "\n",
    "или\n",
    "\n",
    "$$\n",
    "\t\\min_{\\beta} \\frac{1}{n}\\sum_{i=1}^n |y_i-\\beta_0-\\beta_1x_{i1}-\\cdots-\\beta_kx_{ik}|^2\n",
    "$$\n",
    "\n",
    "## Метод наименьших квадратов для линейной регрессии 2D\n",
    "\n",
    "Рассмотрим случай одного предиктора, т.е. $a(x)=\\beta_0+\\beta_1x$ (геометрически прямая на плоскости $(x,y)$). \n",
    "\n",
    "Обозначим (сумма квадратов ошибок прогнозов)\n",
    "\n",
    "$$\n",
    "\tRSS=\\sum_{i=1}^n |y_i-\\hat{y}_i|^2=\\sum_{i=1}^n (y_i-\\beta_0-\\beta_1 x_i)^2\n",
    "$$\n",
    "\n",
    "\n",
    "Коэффициенты подогнанной модели находятся как решение задачи (безусловной) оптимизации\n",
    "\n",
    "$$\n",
    "\t\\min_{\\beta_0,\\beta_1}\\frac{1}{n}RSS\n",
    "$$\n",
    "(на плоскости подгоняем прямую под наблюдения)\n",
    "\n",
    "Необходимые условия\n",
    "\n",
    "$$\n",
    "\t\\left\\{\\begin{aligned} \n",
    "\t\t\\frac{\\partial}{\\partial \\beta_0}\\left(\\frac{1}{n}RSS\\right) &=0 \\\\ \n",
    "\t\t\\frac{\\partial}{\\partial \\beta_1}\\left(\\frac{1}{n}RSS\\right) &=0\n",
    "\t\\end{aligned}\\right.\n",
    "$$\n",
    "\n",
    "Имеем\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\t\\frac{\\partial}{\\partial \\beta_0}\\left(\\frac{1}{n}RSS\\right) &=\\frac{1}{n}\\sum_{i=1}^n 2(y_i-\\beta_0-\\beta_1 x_i)(-1)=\n",
    "\t(-2)\\left(\\frac{1}{n}\\sum_{i=1}^n y_i-\\frac{1}{n}\\sum_{i=1}^n \\beta_0-\\frac{1}{n}\\sum_{i=1}^n \\beta_1x_i\\right)=\n",
    "\t(-2)(\\bar{y}-\\beta_0-\\beta_1 \\bar{x})=0\\\\\n",
    "\t\\frac{\\partial}{\\partial \\beta_1}\\left(\\frac{1}{n}RSS\\right) &=\\frac{1}{n}\\sum_{i=1}^n 2(y_i-\\beta_0-\\beta_1 x_i)(-x_i)=\n",
    "\t(-2)\\left(\\frac{1}{n}\\sum_{i=1}^n x_iy_i-\\frac{1}{n}\\sum_{i=1}^n \\beta_0x_i-\\frac{1}{n}\\sum_{i=1}^n \\beta_1x_i^2\\right)=\n",
    "\t(-2)(\\overline{xy}-\\beta_0\\bar{x}-\\beta_1\\overline{x^2})=0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Получаем систему\n",
    "\n",
    "$$\n",
    "\t\\left\\{\\begin{aligned} \n",
    "\t\t\\beta_0+\\beta_1\\bar{x} &=\\bar{y} \\\\\n",
    "\t\t\\beta_0\\bar{x}+\\beta_1\\overline{x^2} &= \\overline{xy}\n",
    "\t\\end{aligned}\\right.\n",
    "$$\n",
    "\n",
    "Решение системы \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\t\\hat{\\beta}_1 &= \\frac{\\overline{xy}-\\bar{x}\\cdot\\bar{y}}{\\overline{x^2}-\\left(\\bar{x}\\right)^2}=\n",
    "\t\\frac{cov(x,y)}{Var(x)} & \\hat{\\beta}_0&=\\bar{y}-\\hat{\\beta}_1\\cdot\\bar{x}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "__Замечание__: оптимальная прямая $\\hat{y}=\\hat{a}(x)=\\hat{\\beta}_0+\\hat{\\beta}_1x$ проходит через \"центр масс\" \n",
    "наблюдений $(\\bar{x}, \\bar{y})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Численные примеры\n",
    "\n",
    "Подключим необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт данных из файла как DataFrame\n",
    "df = pd.read_csv('sleep75.csv')\n",
    "# размер датафрейма\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-02-17T11:00:53.672981Z",
     "iopub.status.busy": "2024-02-17T11:00:53.672981Z",
     "iopub.status.idle": "2024-02-17T11:00:53.970432Z",
     "shell.execute_reply": "2024-02-17T11:00:53.969430Z",
     "shell.execute_reply.started": "2024-02-17T11:00:53.672981Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# напечатаем датафрейм\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# напечатаем датафрейм\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример 1 2D\n",
    "\n",
    "Рассмотрим регрессию `sleep на totwrk`. Визуализируем данные с оптимальной прямой (библиотека `seaborn`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='darkgrid')\n",
    "sns.regplot(data=df, x='totwrk', y='sleep', ci=None, scatter_kws={'s':5}, line_kws={'linestyle':'dashed', 'color':'r', 'linewidth':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры оптимальной прямой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# спецификация модели через формулу\n",
    "mod = smf.ols(formula='sleep~1+totwrk', data=df)\n",
    "# подгонка модели\n",
    "res = mod.fit()\n",
    "# параметры оптимальной прямой\n",
    "res.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Альтернативная визуализация (библиотека `plotly`). Цвет определяется параметром [trendline_color_override](https://www.w3schools.com/cssref/css_colors.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T10:28:38.507174Z",
     "iopub.status.busy": "2024-02-17T10:28:38.506177Z",
     "iopub.status.idle": "2024-02-17T10:28:38.850318Z",
     "shell.execute_reply": "2024-02-17T10:28:38.850318Z",
     "shell.execute_reply.started": "2024-02-17T10:28:38.507174Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'px' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mpx\u001b[49m\u001b[38;5;241m.\u001b[39mscatter(df, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotwrk\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep\u001b[39m\u001b[38;5;124m'\u001b[39m, trendline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mols\u001b[39m\u001b[38;5;124m'\u001b[39m, trendline_color_override\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#8B0000\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'px' is not defined"
     ]
    }
   ],
   "source": [
    "fig = px.scatter(df, x='totwrk', y='sleep', trendline='ols', trendline_color_override='#8B0000')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример 2 3D\n",
    "\n",
    "Рассмотрим регрессию `sleep на totwrk, age`. Результаты подгонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# спецификация модели через формулу\n",
    "mod = smf.ols(formula='sleep~1+totwrk+age', data=df)\n",
    "# подгонка модели\n",
    "res = mod.fit()\n",
    "# параметры подогнанной модели регрессии\n",
    "res.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "визуализируем данные по переменным модели как 3D диаграмму рассеяния (библиотека `plotly`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(data_frame=df, x='totwrk', y='age', z='sleep')\n",
    "fig.update_traces(marker_size=3) # размер точки\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "визуализируем данные по переменным модели как 3D диаграмму рассеяния с подогнанной плоскостью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# коэффициенты оптимальной плоскости\n",
    "beta0, beta1, beta2 = smf.ols(formula='sleep~1+totwrk+age', data=df).fit().params\n",
    "\n",
    "# Визуализируем данные и плоскость\n",
    "# данные для оптимальной плоскости\n",
    "X = np.arange(start=df['totwrk'].min(), stop=df['totwrk'].max(), step=1)\n",
    "Y = np.arange(start=df['age'].min(), stop=df['age'].max(), step=1)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = beta0+beta1*X+beta2*Y\n",
    "\n",
    "fig = px.scatter_3d(data_frame=df, x='totwrk', y='age', z='sleep')\n",
    "fig.update_traces(marker_size=3) # размер точки\n",
    "fig.add_trace(trace={'type':'surface', 'x':X, 'y':Y, 'z':Z, 'opacity':0.5, 'showscale':False})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример 3 Парабола\n",
    "\n",
    "Рассмотрим регрессию `sleep на totwrk, totwrk^2`. Результаты подгонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# спецификация модели через формулу\n",
    "mod = smf.ols(formula='sleep~1+totwrk+I(totwrk**2)', data=df)\n",
    "# подгонка модели\n",
    "res = mod.fit()\n",
    "# параметры подогнанной модели регрессии\n",
    "res.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# визуализация\n",
    "sns.set_theme(style='darkgrid')\n",
    "sns.regplot(data=df, x='totwrk', y='sleep', order=2, ci=None, scatter_kws={'s':5}, line_kws={'linestyle':'dashed', 'color':'r', 'linewidth':2})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
